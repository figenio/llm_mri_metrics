{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf44f9e5-a505-4562-b8e0-e337dd4cb8f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset, features, ClassLabel, load_from_disk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import researchpy as rp\n",
    "from itertools import chain\n",
    "\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "from networkx.algorithms import bipartite\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "from llm_mri import LLM_MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500869e5-845d-4060-90dd-62ff370f0655",
   "metadata": {},
   "source": [
    "# Carregando os dados e dividindo classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e52001-5881-4431-9acd-fa47956f4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top quantil: 6.0\n",
      "Botton quantil: 4.0\n",
      "All columns ['annotation id', 'original', 'auto', 'organization level', 'global score', 'label']\n",
      "top: 97\n",
      "botton: 81\n",
      "TOTAL: 447\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Infarto agudo do miocárdio apresenta um perfil...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O infarto agudo do miocárdio (IAM) representa ...</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EQUIVALENTES ANGINOSOS: VOMITOS, SUDORESE, DOR...</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IAM é uma doença que afeta o músculo do coraçã...</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Infarto agudo do miocárdio é uma das principai...</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Infarto agudo do miocárdio apresenta um perfil...   top\n",
       "1  O infarto agudo do miocárdio (IAM) representa ...   top\n",
       "2  EQUIVALENTES ANGINOSOS: VOMITOS, SUDORESE, DOR...   mid\n",
       "3  IAM é uma doença que afeta o músculo do coraçã...   mid\n",
       "4  Infarto agudo do miocárdio é uma das principai...   mid"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def label_answer(row, score, botton_quantile, top_quantile):\n",
    "    if (row[score] < botton_quantile):\n",
    "        return 'botton'\n",
    "    elif (row[score] > top_quantile):\n",
    "        return 'top'\n",
    "    else:\n",
    "        return 'mid'\n",
    "        \n",
    "exp = \"_iam\"\n",
    "# exp = \"_dpoc\"\n",
    "lang = \"_pt\"\n",
    "# lang = \"_en\"\n",
    "if \"pt\" in lang:\n",
    "    text_column = 'original'\n",
    "else:\n",
    "    text_column = 'auto'\n",
    "    \n",
    "df_traducao = pd.read_csv('data/experimento_consolidado' + exp + '.csv')\n",
    "\n",
    "score = 'global score'#organization_level,global_score\n",
    "quantile = .3\n",
    "\n",
    "print(\"Top quantil:\", df_traducao[score].quantile(1 - quantile))\n",
    "print(\"Botton quantil:\", df_traducao[score].quantile(quantile))\n",
    "\n",
    "#df_traducao[score].hist()\n",
    "\n",
    "df_traducao['label'] = df_traducao.apply(\n",
    "    label_answer,\n",
    "    axis=1,\n",
    "    score=score,\n",
    "    botton_quantile=df_traducao[score].quantile(quantile),\n",
    "    top_quantile=df_traducao[score].quantile(1 - quantile),\n",
    ")\n",
    "\n",
    "columns_to_remove = list(df_traducao.columns)\n",
    "print(\"All columns\", columns_to_remove)\n",
    "\n",
    "columns_to_remove.remove(text_column)\n",
    "columns_to_remove.remove('label')\n",
    "\n",
    "df_data = df_traducao.rename(columns={text_column: 'text'}).drop(columns=columns_to_remove).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_data['label'].hist()\n",
    "# df_data = df_data.drop(df_data[df_data['label'] == \"mid\"].index).reset_index(drop=True)\n",
    "print(\"top:\", df_data['label'].loc[df_data['label'] == \"top\"].count())\n",
    "print(\"botton:\", df_data['label'].loc[df_data['label'] == \"botton\"].count())\n",
    "print(\"TOTAL:\", df_data['label'].count())\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752e9f3-e1f7-401c-8119-66d822ead646",
   "metadata": {},
   "source": [
    "# Passando os Dados para o Módulo\n",
    "\n",
    "- converte o Dataframe para Dataset;\n",
    "- carrega o modelo e os dados no módulo;\n",
    "- processa as ativações;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820424fd-1bad-4f2e-a52c-1a9c6b237fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████| 447/447 [00:00<00:00, 18005.28 examples/s]\n",
      "Casting the dataset: 100%|█████████| 447/447 [00:00<00:00, 152290.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "subset = Dataset.from_pandas(df_data)\n",
    "subset.cleanup_cache_files()\n",
    "\n",
    "label_feature = subset.features['label']\n",
    "class_names  = subset.unique(\"label\")\n",
    "\n",
    "class_feature = features.ClassLabel(names=sorted(class_names))\n",
    "subset = subset.map(lambda str_value: {\"label\": class_feature.str2int(str_value)}, input_columns=\"label\")\n",
    "\n",
    "subset = subset.cast(features.Features({\n",
    "    \"label\": class_feature,\n",
    "    \"text\": subset.features[\"text\"]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8125f08-83c8-4725-a308-376999be7607",
   "metadata": {},
   "source": [
    "# Classe de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f8a42e-e83f-4636-9ba2-3a158e45cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_metrics:\n",
    "\n",
    "    def __init__(self, Graph, label, model_name, map_dimensions, total_num_of_layers):\n",
    "        self.Graph = Graph\n",
    "        self.label = label\n",
    "        self.model_name = model_name\n",
    "        self.map_dimensions = map_dimensions\n",
    "        self.layers = total_num_of_layers\n",
    "\n",
    "        \"\"\"\n",
    "        Rotulando cada nó com a camada que ele pertence, isso é feito\n",
    "        buscando o primeiro número do seu nome\n",
    "        \"\"\"\n",
    "        for n in self.Graph.nodes:\n",
    "            self.Graph.nodes[n]['layer'] = int(n.split('_')[0])\n",
    "        \n",
    "        self.projection_even, self.projection_odd = self.project_graph()\n",
    "\n",
    "    def project_graph(self):\n",
    "        nodes_even_layers = set()\n",
    "        nodes_odd_layers = set()\n",
    "        \"\"\"\n",
    "        Para fazer a projeção, é necessário que os nós tenham a label\n",
    "        de qual camada pertencem.\n",
    "        \"\"\"\n",
    "        for layer in range(self.layers + 1):\n",
    "            if layer % 2 == 0:\n",
    "                nodes_even_layers = nodes_even_layers.union({ n for n, d in self.Graph.nodes(data=True) if d['layer'] == layer})\n",
    "            else:\n",
    "                nodes_odd_layers = nodes_odd_layers.union({ n for n, d in self.Graph.nodes(data=True) if d['layer'] == layer})\n",
    "\n",
    "        return bipartite.projected_graph(self.Graph, nodes_even_layers), bipartite.projected_graph(self.Graph, nodes_odd_layers)\n",
    "\n",
    "    def get_degree_by_layer(self):\n",
    "        camadas = []\n",
    "        for x in range(self.layers + 1):\n",
    "            camadas.append(str(x))\n",
    "        df_layers = pd.DataFrame(columns=['layer', 'mean', 'var'])\n",
    "\n",
    "        for i in camadas:\n",
    "            df_layers = pd.concat([pd.DataFrame([[\n",
    "                i,\n",
    "                pd.Series([v for k, v in dict(nx.degree(self.Graph)).items() if k.split(\"_\")[0] == i]).mean(),\n",
    "                pd.Series([v for k, v in dict(nx.degree(self.Graph)).items() if k.split(\"_\")[0] == i]).var(),\n",
    "            ]], columns=df_layers.columns), df_layers], ignore_index=True)\n",
    "        \n",
    "        return df_layers.reindex(index=df_layers.index[::-1])\n",
    "\n",
    "    def get_graph_center_of_mass(self):\n",
    "        camadas = []\n",
    "        for x in range(self.layers + 1):\n",
    "            camadas.append(str(x))\n",
    "        \n",
    "        center_of_mass = 0\n",
    "\n",
    "        for i in camadas:\n",
    "            center_of_mass += ((pd.Series([k for k, v in dict(self.Graph.nodes()).items() if k.split(\"_\")[0] == i]).count()) * (int(i) - (self.layers / 2)))\n",
    "        \n",
    "        return center_of_mass / len(list(self.Graph.nodes()))\n",
    "\n",
    "    def get_graph(self):\n",
    "        return self.Graph\n",
    "    \n",
    "    def get_basic_metrics(self):\n",
    "        return {\n",
    "            \"mean_degree\": pd.Series([v for k, v in dict(nx.degree(self.Graph)).items()]).mean(),\n",
    "            \"var_degree\": pd.Series([v for k, v in dict(nx.degree(self.Graph)).items()]).var(),\n",
    "            # \"average_node_connectivity\": nx.average_node_connectivity(self.Graph),\n",
    "            \"assortativity\": nx.degree_assortativity_coefficient(self.Graph),\n",
    "            \"density\": nx.density(self.Graph),\n",
    "            \"center_of_mass\": self.get_graph_center_of_mass(),\n",
    "            \"model_name\": self.model_name,\n",
    "            \"map_dimensions\": self.map_dimensions,\n",
    "            \"label\": self.label\n",
    "        }\n",
    "\n",
    "    def get_projection_metrics_even(self):\n",
    "        return {\n",
    "            \"mean_degree\": pd.Series([v for k, v in dict(nx.degree(self.projection_even)).items()]).mean(),\n",
    "            \"var_degree\": pd.Series([v for k, v in dict(nx.degree(self.projection_even)).items()]).var(),\n",
    "            \"average_clustering\": nx.average_clustering(self.projection_even),\n",
    "            # \"average_node_connectivity\": nx.average_node_connectivity(self.projection_even),\n",
    "            \"assortativity\": nx.degree_assortativity_coefficient(self.projection_even),\n",
    "            \"density\": nx.density(self.projection_even),\n",
    "            \"model_name\": self.model_name,\n",
    "            \"map_dimensions\": self.map_dimensions,\n",
    "            \"label\": self.label,\n",
    "            \"side\": \"even\"\n",
    "        }\n",
    "\n",
    "    def get_projection_metrics_odd(self):\n",
    "        return {\n",
    "            \"mean_degree\": pd.Series([v for k, v in dict(nx.degree(self.projection_odd)).items()]).mean(),\n",
    "            \"var_degree\": pd.Series([v for k, v in dict(nx.degree(self.projection_odd)).items()]).var(),\n",
    "            \"average_clustering\": nx.average_clustering(self.projection_odd),\n",
    "            # \"average_node_connectivity\": nx.average_node_connectivity(self.projection_odd),\n",
    "            \"assortativity\": nx.degree_assortativity_coefficient(self.projection_odd),\n",
    "            \"density\": nx.density(self.projection_odd),\n",
    "            \"model_name\": self.model_name,\n",
    "            \"map_dimensions\": self.map_dimensions,\n",
    "            \"label\": self.label,\n",
    "            \"side\": \"odd\"\n",
    "        }\n",
    "\n",
    "    def get_basic_metrics_list_of_names(self):\n",
    "        return [\n",
    "            'mean_degree',\n",
    "             'var_degree',\n",
    "             'average_clustering',\n",
    "             # 'average_node_connectivity',\n",
    "             'assortativity',\n",
    "             'density',\n",
    "             'model_name',\n",
    "             'map_dimensions',\n",
    "             'label',\n",
    "             'side',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a17cb-2ead-4275-a579-c45390a9fa1d",
   "metadata": {},
   "source": [
    "# Analisando Ativações do Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea04865-0b93-4d4b-9ca9-dcf4954f444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: pierreguillou/gpt2-small-portuguese  -  5  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 5767.57 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [16:01<00:00,  2.15s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n",
      "Loading: pierreguillou/gpt2-small-portuguese  -  10  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 3234.82 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [16:11<00:00,  2.17s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n",
      "Loading: pierreguillou/gpt2-small-portuguese  -  25  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 3082.35 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [15:11<00:00,  2.04s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n",
      "Loading: pucpr/gpt2-bio-pt  -  5  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 3024.36 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [16:40<00:00,  2.24s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n",
      "Loading: pucpr/gpt2-bio-pt  -  10  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 2782.76 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [16:33<00:00,  2.22s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n",
      "Loading: pucpr/gpt2-bio-pt  -  25  -  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/figenio/Projetos/data_science/experimentacao/graph_experimenting/venv/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████| 447/447 [00:00<00:00, 2686.04 examples/s]\n",
      "Map: 100%|█████████████████████████████| 447/447 [17:29<00:00,  2.35s/ examples]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics\n",
      "Saving basic\n",
      "Saving projection\n"
     ]
    }
   ],
   "source": [
    "# Já foram 10:[0,1,2,3,4]\n",
    "# Já foram 20:[0,1,2]\n",
    "\n",
    "models = { \n",
    "    # \"nlpie/tiny-clinicalbert\": 4,          \n",
    "    # \"distilbert-base-uncased\": 6,\n",
    "    # \"google-bert/bert-base-uncased\": 12,\n",
    "    # \"emilyalsentzer/Bio_ClinicalBERT\": 12,\n",
    "    # \"google-bert/bert-large-uncased\": 24,\n",
    "\n",
    "    # \"neuralmind/bert-base-portuguese-cased\": 12, # 110M\n",
    "    # \"pucpr/biobertpt-all\": 12, # 110M\n",
    "    # \"google-bert/bert-base-multilingual-cased\": 12, # 110M\n",
    "    # \"neuralmind/bert-large-portuguese-cased\": 24, # 330M\n",
    "    \n",
    "    # \"openai-community/gpt2\": 12,\n",
    "    # \"openai-community/gpt2-large\": 36\n",
    "    # \"FacebookAI/xlm-roberta-large\": 24,\n",
    "    # \"facebook/xlm-roberta-xl\": 36,          # 3.48B\n",
    "\n",
    "    \n",
    "    \"pierreguillou/gpt2-small-portuguese\": 12, # 1.5B\n",
    "    \"pucpr/gpt2-bio-pt\": 12, # 1.5B\n",
    "}\n",
    "position = 1\n",
    "map_dimensions = [\n",
    "    5,\n",
    "    10,\n",
    "    25\n",
    "]\n",
    "# number_of_layers = 1 + list(models.items())[position][1]\n",
    "\n",
    "# df_basic = pd.DataFrame(columns = ['mean_degree','var_degree','average_node_connectivity','assortativity','density','center_of_mass','model_name','map_dimensions','label'])\n",
    "# df_projection = pd.DataFrame(columns = ['mean_degree','var_degree','average_clustering','average_node_connectivity','assortativity','density','model_name','map_dimensions','label','side'])\n",
    "# df_basic = pd.DataFrame(columns = ['mean_degree','var_degree','assortativity','density','center_of_mass','model_name','map_dimensions','label'])\n",
    "# df_projection = pd.DataFrame(columns = ['mean_degree','var_degree','average_clustering','assortativity','density','model_name','map_dimensions','label','side'])\n",
    "\n",
    "df_basic = pd.read_csv('data/comparison_basic_metrics' + lang + exp + '.csv')\n",
    "df_projection = pd.read_csv('data/comparison_projection_metrics' + lang + exp + '.csv')\n",
    "\n",
    "for model_name, number_of_layers in models.items():\n",
    "    for dimension in map_dimensions:\n",
    "        print(\"Loading:\", model_name, \" - \", dimension, \" - \", number_of_layers)\n",
    "        llm_mri = LLM_MRI(model=model_name, device=\"cpu\", dataset=subset)\n",
    "        llm_mri.process_activation_areas(map_dimension = dimension)\n",
    "        \n",
    "        print(\"Getting metrics\")\n",
    "        G_top = llm_mri.get_graph(\"top\")\n",
    "        G_botton = llm_mri.get_graph(\"botton\")\n",
    "        top_metrics = LLM_metrics(G_top, 'top', model_name.split('/')[-1], dimension, number_of_layers)\n",
    "        botton_metrics = LLM_metrics(G_botton, 'botton',model_name.split('/')[-1], dimension, number_of_layers)\n",
    "\n",
    "        print(\"Saving basic\")\n",
    "        df_basic = pd.concat([pd.DataFrame.from_dict([\n",
    "            top_metrics.get_basic_metrics(),\n",
    "            botton_metrics.get_basic_metrics()\n",
    "        ]), df_basic], ignore_index=True)\n",
    "        \n",
    "        df_basic.to_csv('data/comparison_basic_metrics_pt' + exp + '.csv', index=False)\n",
    "        \n",
    "        print(\"Saving projection\")\n",
    "        df_projection = pd.concat([pd.DataFrame.from_dict([\n",
    "            top_metrics.get_projection_metrics_even(),\n",
    "            top_metrics.get_projection_metrics_odd(),\n",
    "            botton_metrics.get_projection_metrics_even(),\n",
    "            botton_metrics.get_projection_metrics_odd()\n",
    "        ]), df_projection], ignore_index=True)\n",
    "        \n",
    "        df_projection.to_csv('data/comparison_projection_metrics' + lang + exp + '.csv', index=False)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# llm_mri = LLM_MRI(model=list(models.items())[position][0], device=\"cpu\", dataset=subset)\n",
    "\n",
    "# llm_mri.process_activation_areas(map_dimension = map_dimension)\n",
    "\n",
    "# G_top = llm_mri.get_graph(\"top\")\n",
    "# G_botton = llm_mri.get_graph(\"botton\")\n",
    "\n",
    "# img = llm_mri.get_graph_image(G_botton)\n",
    "# plt.box(False)\n",
    "# plt.show()\n",
    "\n",
    "# top_metrics = LLM_metrics(G_top, 'top', list(models.items())[position][0].split('/')[-1], map_dimension, number_of_layers)\n",
    "# botton_metrics = LLM_metrics(G_botton, 'botton', list(models.items())[position][0].split('/')[-1], map_dimension, number_of_layers)\n",
    "\n",
    "# print(\"Exemplo de métricas:\", top_metrics.get_basic_metrics())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sns.lineplot(data=top_metrics.get_degree_by_layer(), x='layer', y='mean', label=\"Top\")\n",
    "# sns.lineplot(data=botton_metrics.get_degree_by_layer(), x='layer', y='mean', label=\"Botton\")\n",
    "\n",
    "# pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_projection_metrics_even(),\n",
    "#     botton_metrics.get_projection_metrics_even()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7491f408-6302-4933-b147-0386b64d122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# models = [ \n",
    "#     # \"nlpie/tiny-clinicalbert\",          \n",
    "#     # \"distilbert-base-uncased\",\n",
    "#     # \"google-bert/bert-base-uncased\",\n",
    "#     # \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "#     # \"google-bert/bert-large-uncased\",\n",
    "    \n",
    "#     # \"openai-community/gpt2\":,\n",
    "#     # \"openai-community/gpt2-large\",\n",
    "#     \"FacebookAI/xlm-roberta-large\",\n",
    "#     # \"facebook/xlm-roberta-xl\",\n",
    "\n",
    "#     \"neuralmind/bert-base-portuguese-cased\",\n",
    "#     \"neuralmind/bert-large-portuguese-cased\",\n",
    "#     \"pucpr/biobertpt-all\",\n",
    "#     \"google-bert/bert-base-multilingual-cased\",\n",
    "#     \"pucpr/gpt2-bio-pt\",\n",
    "#     \"pierreguillou/gpt2-small-portuguese\",\n",
    "# ]\n",
    "\n",
    "# model = AutoModel.from_pretrained(models[6])\n",
    "\n",
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc40b290-40ec-446f-a747-253c3652e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_basic = pd.DataFrame(columns = ['mean_degree','var_degree','average_clustering','average_node_connectivity','assortativity','density','center_of_mass','model_name','map_dimensions','label'])\n",
    "\n",
    "\n",
    "# df_basic\n",
    "\n",
    "\n",
    "# camadas = []\n",
    "# for x in range(12 + 1):\n",
    "#     camadas.append(str(x))\n",
    "        \n",
    "# center_of_mass = 0\n",
    "\n",
    "# for i in camadas:\n",
    "#     print(\"Valor:\", pd.Series([k for k, v in dict(G_top.nodes()).items() if k.split(\"_\")[0] == i]).count())\n",
    "#     print(\"Norm:\", (int(i) - (12 / 2)))\n",
    "#     center_of_mass += (pd.Series([k for k, v in dict(G_top.nodes()).items() if k.split(\"_\")[0] == i]).count() * (int(i) - (12 / 2)))\n",
    "#     print(\"Cent:\", center_of_mass)\n",
    "\n",
    "# center_of_mass / len(list(G_top.nodes()))\n",
    "\n",
    "# [k for k in dict(G_top.nodes()).items() if k.startswith('1')]\n",
    "\n",
    "# [n for n, d in G_top.nodes(data=True) if d['layer'] == 10]\n",
    "\n",
    "# for n in G_top.nodes:\n",
    "#     G_top.nodes[n]['layer'] = int(n.split('_')[0])\n",
    "\n",
    "# [k for k,v in dict(nx.degree(G_top)).items() if k.split(\"_\")[0] == '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11aaf609-c1ae-47d2-9adf-9b66d2cdd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RODA NO PRIMEIRO MODELO\n",
    "\n",
    "# pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_basic_metrics(),\n",
    "#     botton_metrics.get_basic_metrics()\n",
    "# ]).to_csv('data/comparison_basic_metrics.csv', index=False)\n",
    "\n",
    "# pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_projection_metrics_even(),\n",
    "#     top_metrics.get_projection_metrics_odd(),\n",
    "#     botton_metrics.get_projection_metrics_even(),\n",
    "#     botton_metrics.get_projection_metrics_odd()\n",
    "# ]).to_csv('data/comparison_projection_metrics.csv', index=False)\n",
    "\n",
    "# RODA PROS MODELOS SEGUINTES\n",
    "\n",
    "# df_basic = pd.read_csv('data/comparison_basic_metrics.csv')\n",
    "# df_projection = pd.read_csv('data/comparison_projection_metrics.csv')\n",
    "\n",
    "# df_basic = pd.concat([pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_basic_metrics(),\n",
    "#     botton_metrics.get_basic_metrics()\n",
    "# ]), df_basic], ignore_index=True).to_csv('data/comparison_basic_metrics.csv', index=False)\n",
    "\n",
    "# df_projection = pd.concat([pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_projection_metrics_even(),\n",
    "#     top_metrics.get_projection_metrics_odd(),\n",
    "#     botton_metrics.get_projection_metrics_even(),\n",
    "#     botton_metrics.get_projection_metrics_odd()\n",
    "# ]), df_projection], ignore_index=True).to_csv('data/comparison_projection_metrics.csv', index=False)\n",
    "\n",
    "# print(\"rodou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2381ca38-96ce-4528-9941-1ce5cc516455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código que remove duplicatas\n",
    "\n",
    "# df_basic = pd.read_csv('data/comparison_basic_metrics.csv')\n",
    "# df_projection = pd.read_csv('data/comparison_projection_metrics.csv')\n",
    "\n",
    "# df_basic = df_basic.iloc[2:]\n",
    "# df_projection = df_projection.iloc[4:]\n",
    "\n",
    "# df_projection = df_projection.drop(df_projection.index[[8,9]])\n",
    "\n",
    "# df_basic.to_csv('data/comparison_basic_metrics.csv', index=False)\n",
    "# df_projection.to_csv('data/comparison_projection_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5859958c-1197-46c7-aa35-d596895c7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_metrics = []\n",
    "# botton_metrics = []\n",
    "\n",
    "# for G in G_tops:\n",
    "    \n",
    "\n",
    "# top_metrics = LLM_metrics(G_top, 'top', number_of_layers)\n",
    "# botton_metrics = LLM_metrics(G_botton, 'botton', number_of_layers)\n",
    "\n",
    "# # print(\"Exemplo de métricas:\", top_metrics.get_basic_metrics())\n",
    "\n",
    "# # sns.lineplot(data=top_metrics.get_degree_by_layer(), x='layer', y='mean', label=\"Top\")\n",
    "# # sns.lineplot(data=botton_metrics.get_degree_by_layer(), x='layer', y='mean', label=\"Botton\")\n",
    "\n",
    "# pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_projection_metrics_even(),\n",
    "#     botton_metrics.get_projection_metrics_even()\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79213a30-2625-41dd-9522-76fc5735dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comparison = pd.DataFrame(columns=columns_base_metrics_names.append('label'))\n",
    "\n",
    "# df_comparison = pd.concat([pd.DataFrame.from_dict([\n",
    "#     top_metrics.get_projection_metrics_even(),\n",
    "#     botton_metrics.get_projection_metrics_even()\n",
    "# ]), df_comparison], ignore_index=True)\n",
    "\n",
    "# df_comparison"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
